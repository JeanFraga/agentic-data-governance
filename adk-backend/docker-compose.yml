services:
  adk-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: adk-backend
    ports:
      - "8000:8000"
    volumes:
      # Mount Google Cloud credentials for authentication
      - ~/.config/gcloud:/home/appuser/.config/gcloud:ro
      # Optional: Mount local .env file if you want to modify it without rebuilding
      # - ./.env:/home/appuser/.env:ro
    environment:
      # Set the path to Google Cloud credentials
      - GOOGLE_APPLICATION_CREDENTIALS=/home/appuser/.config/gcloud/application_default_credentials.json
      # Optional: Override any environment variables here
      # - GOOGLE_CLOUD_PROJECT=your-project-id
      # - BQ_PROJECT_ID=your-project-id
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/list-apps"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - adk-network

  adk-openai-adapter:
    build:
      context: .
      dockerfile: Dockerfile.adapter
    container_name: adk-openai-adapter
    ports:
      - "8080:8080"
    environment:
      - ADK_API_BASE=http://adk-backend:8000
      - ADK_APP_NAME=data_science_agent
      - ADK_USER_ID=openai_user
      - PORT=8080
      - HOST=0.0.0.0
    depends_on:
      adk-backend:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8080/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - adk-network

  litellm-proxy:
    build:
      context: .
      dockerfile: Dockerfile.litellm
    container_name: litellm-proxy
    ports:
      - "4000:4000"
    environment:
      - LITELLM_MASTER_KEY=litellm-master-key-2024
      - LITELLM_LOG=DEBUG
    depends_on:
      adk-openai-adapter:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - adk-network

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    environment:
      - OPENAI_API_BASE_URL=http://litellm-proxy:4000/v1
      - OPENAI_API_KEY=litellm-master-key-2024
      - WEBUI_SECRET_KEY=your-secret-key-here
      - ENABLE_SIGNUP=false
      - DEFAULT_USER_ROLE=admin
    volumes:
      - open-webui-data:/app/backend/data
    depends_on:
      litellm-proxy:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - adk-network

networks:
  adk-network:
    driver: bridge

volumes:
  open-webui-data:
    driver: local

# Optional: Add volumes for persistent data if needed
# volumes:
#   adk-data:
#     driver: local
