services:
  # ADK Backend Service
  adk-backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: adk-backend
    ports:
      - "8000:8000"
    volumes:
      # Mount Google Cloud credentials for authentication
      - ~/.config/gcloud:/home/appuser/.config/gcloud:ro
    environment:
      # Set the path to Google Cloud credentials
      - GOOGLE_APPLICATION_CREDENTIALS=/home/appuser/.config/gcloud/application_default_credentials.json
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - adk-network

  # Ollama Proxy Service (LiteLLM-based Translation Layer)
  ollama-proxy:
    build:
      context: .
      dockerfile: Dockerfile.ollama-proxy
    container_name: ollama-proxy
    ports:
      - "11434:11434"  # Ollama default port
    volumes:
      # Mount Google Cloud credentials for Vertex AI authentication
      - ~/.config/gcloud:/home/appuser/.config/gcloud:ro
    environment:
      # Proxy configuration
      - PROXY_PORT=11434
      - DEFAULT_MODEL=gemini-2.0-flash-exp
      - LOG_LEVEL=INFO
      
      # Google Cloud / Vertex AI authentication
      - GOOGLE_APPLICATION_CREDENTIALS=/home/appuser/.config/gcloud/application_default_credentials.json
      - GOOGLE_GENAI_USE_VERTEXAI=TRUE
      - VERTEXAI_PROJECT=${GOOGLE_CLOUD_PROJECT:-your-project-id}
      - VERTEXAI_LOCATION=us-central1
      
      # Alternative: Google AI Studio API key (uncomment if preferred)
      # - GOOGLE_AI_STUDIO_API_KEY=${GOOGLE_AI_STUDIO_API_KEY}
      # - GEMINI_API_KEY=${GEMINI_API_KEY}
      
      # Alternative: OpenAI API key (uncomment if preferred)
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
      
      # Alternative: Anthropic API key (uncomment if preferred)
      # - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    depends_on:
      - adk-backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:11434/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - adk-network

  # OpenWebUI Service
  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: openwebui
    ports:
      - "3000:8080"
    volumes:
      - openwebui-data:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama-proxy:11434
      - WEBUI_SECRET_KEY=your-secret-key-here
      - WEBUI_AUTH=false  # Set to true if you want authentication
    depends_on:
      - ollama-proxy
    restart: unless-stopped
    networks:
      - adk-network

networks:
  adk-network:
    driver: bridge

volumes:
  openwebui-data:
    driver: local
